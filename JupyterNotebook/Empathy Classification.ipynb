{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project was made by Dane Zieman\n",
    "\n",
    "In this project, data from https://www.kaggle.com/miroslavsabo/young-people-survey/ is used, the goal is to predict the empathy of an example give the other features. Specifically, the goal is to label people who answered the \"empathy\" question with 1, 2 or 3 as \"not very empathetic\" and people who answered 4 or 5 as \"very empathetic\". In this project a Random Forest and a Neural Network will be used to accomplish this task.\n",
    "\n",
    "First, make sure you have all the appropriate modules installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "2.1.6-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: Tensor Keras version number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, begin by loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the raw data\n",
    "filenames = []\n",
    "dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "filename = dir_path + \"/responses.csv\"\n",
    "\n",
    "npFeatures=pd.read_csv(filename, sep=',',header=0)\n",
    "#extract the labels\n",
    "npLabels2=[]\n",
    "for z in npFeatures.values:\n",
    "    npLabels2.append(z[94])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is loaded, it needs to be preprocessed. All categorical features need to be converted to numerical data as TensorFlow cannot run on categorical data. Additionally, any example that does not have an empathy value must be removed and all NaN entries must be fixed. For this assignement, all NaNs were replaced with the column average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all examples that don't have our target labelled\n",
    "removeInd = []\n",
    "for z in range(len(npLabels2)):\n",
    "    if np.isnan(npLabels2[z]):\n",
    "        removeInd.append(z)\n",
    "    else:\n",
    "        if npLabels2[z] > 3:\n",
    "            npLabels2[z] = 1\n",
    "        else:\n",
    "            npLabels2[z] = 0\n",
    "\n",
    "npFeatures2 = []\n",
    "\n",
    "for z in range(len(npFeatures)):\n",
    "    if z not in removeInd:\n",
    "        npFeatures2.append(npFeatures.values[z])\n",
    "\n",
    "npLabels2 = np.delete(npLabels2,removeInd)\n",
    "\n",
    "#Preprocessing the categorical features\n",
    "for z in range(len(npFeatures2)):\n",
    "    if (npFeatures2[z][73] == \"never smoked\"):\n",
    "        npFeatures2[z][73] = 1\n",
    "    elif (npFeatures2[z][73] == \"tried smoking\"):\n",
    "        npFeatures2[z][73] = 2\n",
    "    elif (npFeatures2[z][73] == \"former smoker\"):\n",
    "        npFeatures2[z][73] = 3\n",
    "    elif (npFeatures2[z][73] == \"current smoker\"):\n",
    "        npFeatures2[z][73] = 4\n",
    "    if (npFeatures2[z][74] == \"never\"):\n",
    "        npFeatures2[z][74] = 1\n",
    "    elif (npFeatures2[z][74] ==\"social drinker\"):\n",
    "        npFeatures2[z][74] = 2\n",
    "    elif (npFeatures2[z][74] ==\"drink a lot\"):\n",
    "        npFeatures2[z][74] = 3\n",
    "    if (npFeatures2[z][107] == \"i am often early\"):\n",
    "        npFeatures2[z][107] = 1\n",
    "    elif (npFeatures2[z][107] == \"i am always on time\"):\n",
    "        npFeatures2[z][107] = 2\n",
    "    elif (npFeatures2[z][107] == \"i am often running late\"):\n",
    "        npFeatures2[z][107] = 3\n",
    "    if (npFeatures2[z][108] == \"never\"):\n",
    "        npFeatures2[z][108] = 1\n",
    "        npFeatures2[z][94] = 1 #reusing the space that used to store the label\n",
    "        #use it to store whether or not they lie pathologically\n",
    "    elif (npFeatures2[z][108] == \"only to avoid hurting someone\"):\n",
    "        npFeatures2[z][108] = 1\n",
    "        npFeatures2[z][94] = 1\n",
    "    elif (npFeatures2[z][108] == \"sometimes\"):\n",
    "        npFeatures2[z][108] = 2\n",
    "        npFeatures2[z][94] = 1\n",
    "    elif (npFeatures2[z][108] == \"everytime it suits me\"):\n",
    "        npFeatures2[z][108] = 3\n",
    "        npFeatures2[z][94] = 2\n",
    "    if (npFeatures2[z][132] == \"no time at all\"):\n",
    "        npFeatures2[z][132] = 1\n",
    "    elif (npFeatures2[z][132] == \"less than an hour a day\"):\n",
    "        npFeatures2[z][132] = 2\n",
    "    elif (npFeatures2[z][132] == \"few hours a day\"):\n",
    "        npFeatures2[z][132] = 3\n",
    "    elif (npFeatures2[z][132] == \"most of the day\"):\n",
    "        npFeatures2[z][132] = 4\n",
    "    if (npFeatures2[z][144] == \"male\"):\n",
    "        npFeatures2[z][144] = 1\n",
    "    elif (npFeatures2[z][144] == \"female\"):\n",
    "        npFeatures2[z][144] = 2\n",
    "    if (npFeatures2[z][145] == \"right handed\"):\n",
    "        npFeatures2[z][145] = 1\n",
    "    elif (npFeatures2[z][145] == \"left handed\"):\n",
    "        npFeatures2[z][145] = 2\n",
    "    if (npFeatures2[z][146] == \"currently a primary school pupil\"):\n",
    "        npFeatures2[z][146] = 1\n",
    "    elif (npFeatures2[z][146] == \"primary school\"):\n",
    "        npFeatures2[z][146] = 2\n",
    "    elif (npFeatures2[z][146] == \"secondary school\"):\n",
    "        npFeatures2[z][146] = 3\n",
    "    elif (npFeatures2[z][146] == \"college/bachelor degree\"):\n",
    "        npFeatures2[z][146] = 4\n",
    "    elif (npFeatures2[z][146] == \"masters degree\"):\n",
    "        npFeatures2[z][146] = 5\n",
    "    elif (npFeatures2[z][146] == \"doctorate degree\"):\n",
    "        npFeatures2[z][146] = 6\n",
    "    if (npFeatures2[z][147] == \"no\"):\n",
    "        npFeatures2[z][147] = 1\n",
    "    elif (npFeatures2[z][147] == \"yes\"):\n",
    "        npFeatures2[z][147] = 2\n",
    "    if (npFeatures2[z][148] == \"village\"):\n",
    "        npFeatures2[z][148] = 1\n",
    "    elif (npFeatures2[z][148] == \"city\"):\n",
    "        npFeatures2[z][148] = 2\n",
    "    if (npFeatures2[z][149] == \"block of flats\"):\n",
    "        npFeatures2[z][149] = 1\n",
    "    elif (npFeatures2[z][149] == \"house/bungalow\"):\n",
    "        npFeatures2[z][149] = 2\n",
    "\n",
    "#replace all nans with an average value\n",
    "for z in range(len(npFeatures2[1])):\n",
    "    avg = 0\n",
    "    for i in range(len(npFeatures2)):\n",
    "        if (np.isnan(npFeatures2[i][z])):\n",
    "            continue\n",
    "        else:\n",
    "            avg += npFeatures2[i][z]\n",
    "    avg = math.floor(avg / len(npFeatures2))\n",
    "    for i in range(len(npFeatures2)):\n",
    "        if (np.isnan(npFeatures2[i][z])):\n",
    "            npFeatures2[i][z] = avg\n",
    "\n",
    "npFeatures2 = np.array(npFeatures2)\n",
    "npLabels2 = np.array(npLabels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, npFeatures2 and npLabels2 are numpy arrays that hold all the data and all the labels. The next step is to build a baseline classifier for this model. For this, the majority classifier will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do most frequent classifier\n",
    "count = [0, 0]\n",
    "for z in npLabels2:\n",
    "    t = int(z)\n",
    "    count[t-1] += 1\n",
    "\n",
    "label = 1\n",
    "if (count[0] < count[1]):\n",
    "    label = 2\n",
    "\n",
    "misses = 0\n",
    "for z in npLabels2:\n",
    "    t = int(z)\n",
    "    if t != label:\n",
    "        misses += 1\n",
    "\n",
    "numLabels = npLabels2.size\n",
    "print(\"Most Frequent Classifier Accuracy: \" + str((numLabels-misses)/numLabels) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: Roughly 0.667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to do a train-test split. For this project, a 90-10 split will be used. From this 90% training data, it will further be split into 75% training 15% validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a test train split (roughly 75-15-10 train-valid-test random split)\n",
    "randomindices = np.arange(1005)\n",
    "np.random.shuffle(randomindices)\n",
    "test_data = npFeatures2[randomindices[905:]]\n",
    "test_labels = npLabels2[randomindices[905:]]\n",
    "training_set = npFeatures2[randomindices[:905]]\n",
    "label_set = npLabels2[randomindices[:905]]\n",
    "randomindices = np.arange(905)\n",
    "training_data = training_set[randomindices[:755]]\n",
    "training_labels = label_set[randomindices[:755]]\n",
    "validation_data = training_set[randomindices[755:905]]\n",
    "validation_labels = label_set[randomindices[755:905]] \n",
    "\n",
    "#save the test data and labels to a file\n",
    "np.save(\"Processed_Test_Data\", test_data)\n",
    "np.save(\"Processed_Test_Labels\", test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the neural network will be built. This neural network is built using TensorFlow's Keras The class weights and model layers where chosen by iteration after testing a bunch of different choices on the model. Some choices, like poor weight choices, or by adding softmax layers to certain points of the model will cause the model to simply predict the majority every time. Try experimenting with different weights and layers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the tensor flow model\n",
    "class_weight = {0: 1.,\n",
    "                1: 2.}\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(150, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='selu'))\n",
    "model.add(layers.Dense(128, activation='sigmoid'))\n",
    "model.add(layers.Dense(128, activation='selu'))\n",
    "model.add(layers.Dense(128, activation='sigmoid'))\n",
    "model.add(layers.Dense(64, activation='selu'))\n",
    "model.add(layers.Dense(64, activation='sigmoid'))\n",
    "model.add(layers.Dense(64, activation='selu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='selu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.0008),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(training_data, training_labels, epochs=50, batch_size=32,\n",
    "          validation_data=(validation_data, validation_labels), class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to try to improve the model is to try different validation/test splits and see if these improve the model vs the majority classifier. For example, if the train/validation split is biased towards the positive class, the model may get a good score but not be significantly better than the majority classifier. This code below trys to find a model that does the best vs the majority classifier for different train/validation splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare to most frequent classifier\n",
    "count = [0, 0]\n",
    "for z in validation_labels:\n",
    "    t = int(z)\n",
    "    count[t-1] += 1\n",
    "\n",
    "label = 1\n",
    "if (count[0] < count[1]):\n",
    "    label = 2\n",
    "\n",
    "misses = 0\n",
    "for z in validation_labels:\n",
    "    t = int(z)\n",
    "    if t != label:\n",
    "        misses += 1\n",
    "MFCacc = (len(validation_labels)-misses)/len(validation_labels)\n",
    "acc = result[1]\n",
    "maxDiff = acc - MFCacc\n",
    "used_validation = validation_data\n",
    "used_labels = validation_labels\n",
    "\n",
    "#Do 10 more comparisons to the majority classifier\n",
    "for z in range(10): \n",
    "    print(\"Cross Training run #\" + str(z+1) + \"/10\")\n",
    "    randomindices = np.arange(905)\n",
    "    np.random.shuffle(randomindices)\n",
    "    training_data = training_set[randomindices[:755]]\n",
    "    training_labels = label_set[randomindices[:755]] \n",
    "    validation_data = training_set[randomindices[755:905]]\n",
    "    validation_labels = label_set[randomindices[755:905]] \n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(150, activation='relu'))\n",
    "    model.add(layers.Dense(128, activation='selu'))\n",
    "    model.add(layers.Dense(128, activation='sigmoid'))\n",
    "    model.add(layers.Dense(128, activation='selu'))\n",
    "    model.add(layers.Dense(128, activation='sigmoid'))\n",
    "    model.add(layers.Dense(64, activation='selu'))\n",
    "    model.add(layers.Dense(64, activation='sigmoid'))\n",
    "    model.add(layers.Dense(64, activation='selu'))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(16, activation='selu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=tf.train.AdamOptimizer(0.0008),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "    model.fit(training_data, training_labels, epochs=50, batch_size=32,\n",
    "            validation_data=(validation_data, validation_labels), class_weight=class_weight, verbose = 0)\n",
    "\n",
    "    #inspect the individual results on the test data\n",
    "    result = model.evaluate(validation_data, validation_labels, batch_size=32)\n",
    "    loss = result[0]\n",
    "    acc = result[1]\n",
    "    print(result)\n",
    "    #compare to most frequent classifier\n",
    "    #Do most frequent classifier\n",
    "    count = [0, 0]\n",
    "    for z in validation_labels:\n",
    "        t = int(z)\n",
    "        count[t-1] += 1\n",
    "\n",
    "    label = 1\n",
    "    if (count[0] < count[1]):\n",
    "        label = 2\n",
    "\n",
    "    misses = 0\n",
    "    for z in validation_labels:\n",
    "        t = int(z)\n",
    "        if t != label:\n",
    "            misses += 1\n",
    "    MFCacc = (len(validation_labels)-misses)/len(validation_labels)\n",
    "    diff = acc - MFCacc\n",
    "    print(diff)\n",
    "    if (diff > maxDiff):\n",
    "        maxDiff = diff\n",
    "        theModel = model\n",
    "        used_validation = validation_data\n",
    "        used_labels = validation_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model will be selected from the 11 runs. Now that the model is fully built it is time to have it attempt the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect the individual results on the test data\n",
    "print(\"Testing\")\n",
    "result = theModel.evaluate(test_data, test_labels, batch_size=32)\n",
    "print(result)\n",
    "result = theModel.predict_classes(test_data, batch_size=32)\n",
    "confusionMat = confusion_matrix(test_labels, result)\n",
    "print(confusionMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: Loss, accuracy and confusion matrix for the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting results from the validation data can be observed as well. For this data set, classifications of the negative class are most interesting, so those will be output with the code below. Feel free to change the output statements to look at different predcitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interesting validation results\n",
    "result = theModel.predict_classes(used_validation, batch_size=32)\n",
    "c = 0\n",
    "comparisons = []\n",
    "for z in range(len(result)):\n",
    "    if (result[z][0] == 0 and used_labels[z] == 0):\n",
    "        comparisons.append(\"Prediction #\" + str(z) +\":\" + str(result[z][0]) + \" Label:\"+str(used_labels[z]))\n",
    "    if (result[z][0] == 0 and used_labels[z] == 1):\n",
    "        comparisons.append(\"Prediction #\" + str(z) +\":\" + str(result[z][0]) + \" Label:\"+str(used_labels[z]))\n",
    "for z in comparisons:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model architecture can also be exported to a JSON, and the weights can be exported as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('tensorModel_weights.h5')\n",
    "with open('tensorModel_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all there is to do for the neural network, next is the random forest classifier. Sklearn's RandomForestClassifier was used for this, and the same train-test data split will be used for this as well. Like the previous example, the class weights, number of trees in the forest, and the max height of the tree where chosen by iteration. If the max tree height was less than 5 and the class weights were chosen poorly, the random forest would be close to or exactly the majority classifier. Feel free to experiment with these hyperparameters if you choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the first random forest\n",
    "randomindices = np.arange(905)\n",
    "np.random.shuffle(randomindices)\n",
    "cross_training_data = training_set[randomindices[:755]]\n",
    "cross_training_labels = label_set[randomindices[:755]] \n",
    "validation_data = training_set[randomindices[755:905]]\n",
    "validation_labels = label_set[randomindices[755:905]]  \n",
    "clf = RandomForestClassifier(n_estimators=500, max_depth=11, random_state = 0, class_weight = class_weight)\n",
    "clf.fit(cross_training_data, cross_training_labels)\n",
    "result = clf.predict(validation_data)\n",
    "print(result)\n",
    "c = 0\n",
    "for z in range(len(result)):\n",
    "    if (result[z] == validation_labels[z]):\n",
    "        c +=1\n",
    "score = c/len(result)\n",
    "print(str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like for the neural network, it is desirable to compare this model to the majority classifier, and try different train-validation splits to get the model that outperform the majority classifier the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theclf = clf\n",
    "#compare to most frequent\n",
    "count = [0, 0]\n",
    "for z in validation_labels:\n",
    "    t = int(z)\n",
    "    count[t-1] += 1\n",
    "\n",
    "label = 1\n",
    "if (count[0] < count[1]):\n",
    "    label = 2\n",
    "\n",
    "misses = 0\n",
    "for z in validation_labels:\n",
    "    t = int(z)\n",
    "    if t != label:\n",
    "        misses += 1\n",
    "MFCacc = (len(validation_labels)-misses)/len(validation_labels)\n",
    "maxDiff = score - MFCacc\n",
    "\n",
    "#try 10 different train-validation splits\n",
    "for z in range(10):\n",
    "    randomindices = np.arange(905)\n",
    "    np.random.shuffle(randomindices)\n",
    "    cross_training_data = training_set[randomindices[:755]]\n",
    "    cross_training_labels = label_set[randomindices[:755]] \n",
    "    validation_data = training_set[randomindices[755:905]]\n",
    "    validation_labels = label_set[randomindices[755:905]]  \n",
    "    clf = RandomForestClassifier(n_estimators=500, max_depth=11, random_state = 0, class_weight = class_weight)\n",
    "    clf.fit(cross_training_data, cross_training_labels)\n",
    "    result = clf.predict(validation_data)\n",
    "    print(result)\n",
    "    c = 0\n",
    "    for z in range(len(result)):\n",
    "        if (result[z] == validation_labels[z]):\n",
    "            c +=1\n",
    "    score = c/len(result)\n",
    "    print(str(score))\n",
    "    #compare to most frequent\n",
    "    count = [0, 0]\n",
    "    for z in validation_labels:\n",
    "        t = int(z)\n",
    "        count[t-1] += 1\n",
    "\n",
    "    label = 1\n",
    "    if (count[0] < count[1]):\n",
    "        label = 2\n",
    "\n",
    "    misses = 0\n",
    "    for z in validation_labels:\n",
    "        t = int(z)\n",
    "        if t != label:\n",
    "            misses += 1\n",
    "    MFCacc = (len(validation_labels)-misses)/len(validation_labels)\n",
    "    diff = score - MFCacc\n",
    "    print(diff)\n",
    "    if (diff > maxDiff):\n",
    "        theclf = clf\n",
    "        maxDiff=diff\n",
    "        used_validation = validation_data\n",
    "        used_labels = validation_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this, the random forest model is built. Now it is time to try it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict(test_data)\n",
    "confusionMat = confusion_matrix(test_labels, result)\n",
    "print(confusionMat)\n",
    "c = 0\n",
    "for z in range(len(result)):\n",
    "    if (result[z] == test_labels[z]):\n",
    "        c +=1\n",
    "score = c/len(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also useful to look at interesting examples from the validation data. Below is code to look at all the examples that are classified as 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clf.predict(used_validation)\n",
    "print(str(score))\n",
    "comparisons = []\n",
    "for z in range(len(result)):\n",
    "    if (result[z] == 0 and used_labels[z] == 0):\n",
    "        comparisons.append(\"Prediction #\" + str(z) +\":\" + str(result[z]) + \" Label:\"+str(used_labels[z]))\n",
    "    if (result[z] == 0 and used_labels[z] == 1):\n",
    "        comparisons.append(\"Prediction #\" + str(z) +\":\" + str(result[z]) + \" Label:\"+str(used_labels[z]))\n",
    "for z in comparisons:\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful feature that the random forest has that the neural network does not, is the ability to see the importance of each individual feature. Below is the code to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureWeights = list(zip(npFeatures, theclf.feature_importances_))\n",
    "#Fix the naming error for the bin we reused\n",
    "for z in featureWeights:\n",
    "    if z[0] == 'Empathy':\n",
    "        temp = ('Pathological Liar?', z[1])\n",
    "        featureWeights.remove(z)\n",
    "        featureWeights.append(temp)\n",
    "featureWeights.sort(key=lambda x: x[1], reverse=True)\n",
    "print(featureWeights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(theclf, 'randomForest.joblib') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "TensorFlow Keras: https://www.tensorflow.org/guide/keras\n",
    "\n",
    "Sklearn RandomForestClassifier: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
